{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cd35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                 | 0/22 [00:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 137, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as ni\n",
    "import os, shutil\n",
    "import time\n",
    "import random\n",
    "import pandas as pd \n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "import loss\n",
    "from dataset import MRI_dataloader\n",
    "from model import VAE\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "ckpt_path = path2save = \"./checkpoint/model_vae_epoch_{}.pt\"\n",
    "ckpt_path = ckpt_path.format(52)\n",
    "path = 'dataset/images'\n",
    "mri_loader = MRI_dataloader(path)\n",
    "batch_size = 8\n",
    "dataloader = DataLoader(mri_loader, batch_size=batch_size, shuffle=True)\n",
    "model = VAE().to(device)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_csv('dataset/data.csv')\n",
    "\n",
    "# model.eval()\n",
    "# for batch in tqdm(dataloader):\n",
    "#     batch = batch.to(device)\n",
    "#     y, z_mean, z_log_sigma = model(batch)\n",
    "#     print(y.shape)\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "243bc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 512\n",
    "epsilon = torch.normal(size=(1, latent_dim), mean=0, std=1.0, device=device)\n",
    "z = z_mean + z_log_sigma.exp()*epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9ad348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "171e300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "import nibabel as ni\n",
    "\n",
    "def preprocess_image(path, filename, img_size=(137, 128, 128)):\n",
    "    image = ni.load(os.path.join(path, filename)) #self.filenames[index]\n",
    "    image = np.array(image.dataobj)\n",
    "    image = np.moveaxis(image, [0, 1], [1, 0])\n",
    "    img_scale = tuple([img_size[i]/image.shape[i] for i in range(len(image.shape))])\n",
    "    image = zoom(image, img_scale)\n",
    "    image = image / 255.\n",
    "    image = torch.from_numpy(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    #image = torch.permute(image, (1, 0, 2)).unsqueeze(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28226294",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [i for i in os.listdir(path) if i.endswith(\".nii\")]\n",
    "model.eval()\n",
    "PT_500 = []\n",
    "PT_4000 = []\n",
    "latents = []\n",
    "for filename in filenames:\n",
    "    img = preprocess_image(path, filename)\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "    y, z_mean, z_log_sigma = model(img)\n",
    "    latent = z_mean + z_log_sigma.exp()*epsilon\n",
    "    \n",
    "    filename_ = filename.split('_')[0]\n",
    "    fl = filename_[:5] + '_' + filename_[5:]\n",
    "    PT_500.append(labels[labels['ID'] == fl]['PT500'][0])\n",
    "    PT_4000.append(labels[labels['ID'] == fl]['PT4000'][0])\n",
    "    latents.append(latent.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 70 30 for training and testing\n",
    "# train model on 70 and test on 30%\n",
    "# report rmse scores for different models\n",
    "# add data augmentation and train again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-a100",
   "language": "python",
   "name": "pytorch-a100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
