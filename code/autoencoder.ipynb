{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a241c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import math \n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e90a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((W - K + 2p)/s) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c83fcc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_block(nn.Module):\n",
    "    \"A ResNet-like block with the GroupNorm normalization providing optional bottle-neck functionality\"\n",
    "    def __init__(self, ch, k_size=3, stride=1, p=1, num_groups=1):\n",
    "        super(ResNet_block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(ch, ch, kernel_size=k_size, stride=stride, padding=p), \n",
    "            nn.BatchNorm3d(ch),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Conv3d(ch, ch, kernel_size=k_size, stride=stride, padding=p),  \n",
    "            nn.BatchNorm3d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x) + x\n",
    "        return out\n",
    "\n",
    "# ch = 1\n",
    "# h = 113\n",
    "# w = 113\n",
    "# s = 137\n",
    "# b = 2\n",
    "# input = torch.randn(b, ch, s, h, w).to(torch.float32).to(device)\n",
    "# net = ResNet_block(ch, 3).to(device)\n",
    "# out = net(input)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f497a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, k_size=3, stride=1, p=1, num_groups=1):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(ch_in, ch_out, kernel_size=k_size, stride=stride, padding=p),  \n",
    "            nn.BatchNorm3d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "\n",
    "# ch_in = 128\n",
    "# h = 113\n",
    "# w = 113\n",
    "# s = 137\n",
    "# b = 2\n",
    "# ch_out = 64 \n",
    "# k_size = 3\n",
    "# input = torch.randn(b, ch_in, s, h, w).to(torch.float32).to(device)\n",
    "# net = conv_block(ch_in, ch_out, k_size).to(device)\n",
    "# out = net(input)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16918e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class up_conv(nn.Module):\n",
    "    \"Reduce the number of features by 2 using Conv with kernel size 1x1x1 and double the spatial dimension using 3D trilinear upsampling\"\n",
    "    def __init__(self, ch_in, ch_out, k_size=(1,2,2), stride=(1,2,2), p=(0,0,0)):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            #nn.Conv3d(ch_in, ch_out, kernel_size=k_size),\n",
    "            #nn.Upsample(scale_factor=scale, mode='trilinear', align_corners=align_corners),\n",
    "            nn.ConvTranspose3d(ch_in, ch_out, k_size, stride=stride, padding=p),\n",
    "            nn.BatchNorm3d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "\n",
    "    \n",
    "# ch_in = 128\n",
    "# h = 128\n",
    "# w = 128\n",
    "# s = 137\n",
    "# b = 2\n",
    "# ch_out = 64 \n",
    "# k_size = 2\n",
    "# input = torch.randn(b, ch_in, s, h, w).to(torch.float32).to(device)\n",
    "# net = up_conv(ch_in, ch_out).to(device)\n",
    "# out = net(input)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7d67065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 137, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "up = nn.ConvTranspose3d(8, 8, (1,2,2), stride=(2,2,2), padding=(0,0,0)).to(device)\n",
    "scale = (137/68,2,2)\n",
    "up = nn.Upsample(scale_factor=scale, mode='trilinear', align_corners=True)\n",
    "\n",
    "b = 2\n",
    "ch_in = 8\n",
    "s = 68\n",
    "h = 16\n",
    "w = 16\n",
    "input = torch.randn(b, ch_in, s, h, w).to(torch.float32).to(device)\n",
    "out = up(input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6319e619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.014705882352941"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "137/68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "347d44d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 137, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "class up_sample_conv(nn.Module):\n",
    "    \"Reduce the number of features by 2 using Conv with kernel size 1x1x1 and double the spatial dimension using 3D trilinear upsampling\"\n",
    "    def __init__(self, ch_in, ch_out, scale, k_size=3, stride=1, p=1, align_corners=True):\n",
    "        super(up_sample_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=scale, mode='trilinear', align_corners=align_corners),\n",
    "            nn.Conv3d(ch_in, ch_out, kernel_size=k_size, stride=stride, padding=p),\n",
    "            nn.BatchNorm3d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "scale = (137/68,2,2)\n",
    "\n",
    "b = 2\n",
    "ch_in = 8\n",
    "ch_out = 8\n",
    "s = 68\n",
    "h = 16\n",
    "w = 16\n",
    "input = torch.randn(b, ch_in, s, h, w).to(torch.float32).to(device)\n",
    "up_sample = up_sample_conv(ch_in, ch_out, scale).to(device)\n",
    "out = up_sample(input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51e0aa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 9, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# 128 -> 64 -> 32 -> 16 -> 8\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" Encoder module \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        start_val = 4\n",
    "        self.conv1 = conv_block(ch_in=1, ch_out=start_val, k_size=3, num_groups=1)\n",
    "        self.res_block1 = ResNet_block(ch=start_val, k_size=3, num_groups=8)\n",
    "        self.MaxPool1 = nn.MaxPool3d(3, stride=2, padding=1)\n",
    "#         self.MaxPool1 = nn.MaxPool3d((3,3,3), stride=(2,2,2), padding=(0,1,1))\n",
    "\n",
    "        self.conv2 = conv_block(ch_in=start_val, ch_out=start_val*2, k_size=3, num_groups=8)\n",
    "        self.res_block2 = ResNet_block(ch=start_val*2, k_size=3, num_groups=16)\n",
    "        self.MaxPool2 = nn.MaxPool3d(3, stride=2, padding=1)\n",
    "#         self.MaxPool2 = nn.MaxPool3d((3,3,3), stride=(1,2,2), padding=(0,1,1))\n",
    "        \n",
    "\n",
    "        self.conv3 = conv_block(ch_in=start_val*2, ch_out=start_val*4, k_size=3, num_groups=16)\n",
    "        self.res_block3 = ResNet_block(ch=start_val*4, k_size=3, num_groups=16)\n",
    "        self.MaxPool3 = nn.MaxPool3d(3, stride=2, padding=1)\n",
    "#         self.MaxPool3 = nn.MaxPool3d((3,3,3), stride=(1,2,2), padding=(0,1,1))\n",
    "\n",
    "        self.conv4 = conv_block(ch_in=start_val*4, ch_out=start_val*8, k_size=3, num_groups=16)\n",
    "        self.res_block4 = ResNet_block(ch=start_val*8, k_size=3, num_groups=16)\n",
    "        self.MaxPool4 = nn.MaxPool3d(3, stride=2, padding=1)\n",
    "#         self.MaxPool4 = nn.MaxPool3d((3,3,3), stride=(1,2,2), padding=(0,1,1))\n",
    "\n",
    "        self.reset_parameters()\n",
    "      \n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            stdv = 1.0 / math.sqrt(weight.size(0))\n",
    "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.res_block1(x1)\n",
    "        x1 = self.MaxPool1(x1) # torch.Size([1, 32, 26, 31, 26])\n",
    "        \n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.res_block2(x2)\n",
    "        x2 = self.MaxPool2(x2) # torch.Size([1, 64, 8, 10, 8])\n",
    "\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = self.res_block3(x3)\n",
    "        x3 = self.MaxPool3(x3) # torch.Size([1, 128, 2, 3, 2])\n",
    "        \n",
    "        x4 = self.conv4(x3)\n",
    "        x4 = self.res_block4(x4) # torch.Size([1, 256, 2, 3, 2])\n",
    "        x4 = self.MaxPool4(x4) # torch.Size([1, 256, 1, 1, 1])\n",
    "#         print(\"x1 shape: \", x1.shape)\n",
    "#         print(\"x2 shape: \", x2.shape)\n",
    "#         print(\"x3 shape: \", x3.shape)\n",
    "#         print(\"x4 shape: \", x4.shape) \n",
    "        return x4\n",
    "\n",
    "ch_in = 1\n",
    "h = 128\n",
    "w = 128\n",
    "s = 137\n",
    "b = 2\n",
    "ch_out = 64 \n",
    "k_size = 2\n",
    "input = torch.randn(b, ch_in, s, h, w).to(torch.float32).to(device)\n",
    "net = Encoder().to(device)\n",
    "out = net(input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "837fa53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18432"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*9*8*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750aee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7151dc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 18, 16, 16])\n",
      "torch.Size([2, 16, 35, 32, 32])\n",
      "torch.Size([2, 8, 69, 64, 64])\n",
      "torch.Size([2, 4, 137, 128, 128])\n",
      "torch.Size([2, 1, 137, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\" Decoder Module \"\"\"\n",
    "    def __init__(self, latent_dim, prev_dim = 32*9*8*8):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        #self.linear_up = nn.Linear(latent_dim, 256*9*8*8)\n",
    "        \n",
    "        self.linear_up = nn.Sequential(nn.Linear(latent_dim, prev_dim//8),\n",
    "                                   nn.BatchNorm1d(prev_dim//8),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(prev_dim//8, prev_dim),\n",
    "                                   nn.BatchNorm1d(prev_dim),\n",
    "                                   nn.ReLU())\n",
    "\n",
    "        #up_sample_conv(ch_in, ch_out, scale)\n",
    "        #self.relu = nn.ReLU()\n",
    "        \n",
    "        self.upsize4 = up_sample_conv(ch_in=32, ch_out=32, scale=(18/9, 2, 2))\n",
    "        self.res_block4 = ResNet_block(ch=32, k_size=3, num_groups=16)\n",
    "        \n",
    "        self.upsize3 = up_sample_conv(ch_in=32, ch_out=16, scale=(35/18, 2, 2))\n",
    "        self.res_block3 = ResNet_block(ch=16, k_size=3, num_groups=16)        \n",
    "        \n",
    "        self.upsize2 = up_sample_conv(ch_in=16, ch_out=8, scale=(69/35, 2, 2))\n",
    "        self.res_block2 = ResNet_block(ch=8, k_size=3, num_groups=16)   \n",
    "        \n",
    "        self.upsize1 = up_sample_conv(ch_in=8, ch_out=4, scale=(137/69, 2, 2))\n",
    "        self.res_block1 = ResNet_block(ch=4, k_size=3, num_groups=1)\n",
    "        \n",
    "        self.out_conv = conv_block(ch_in=4, ch_out=1)\n",
    "\n",
    "\n",
    "        self.reset_parameters()\n",
    "      \n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            stdv = 1.0 / math.sqrt(weight.size(0))\n",
    "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x4_ = self.linear_up(x)\n",
    "        #x4_ = self.relu(x4_)\n",
    "        #print('x4 shape - ',x4_.shape)\n",
    "\n",
    "        x4_ = x4_.view(-1, 32, 9, 8, 8)\n",
    "        #print()\n",
    "        # x4_ = x4_.view(-1, 256, 9, 8, 8)\n",
    "\n",
    "        x4_ = self.upsize4(x4_) \n",
    "        x4_ = self.res_block4(x4_)\n",
    "        print(x4_.shape)\n",
    "\n",
    "        x3_ = self.upsize3(x4_) \n",
    "        x3_ = self.res_block3(x3_)\n",
    "        print(x3_.shape)\n",
    "        \n",
    "        x2_ = self.upsize2(x3_) \n",
    "        x2_ = self.res_block2(x2_)\n",
    "        print(x2_.shape)\n",
    "\n",
    "        x1_ = self.upsize1(x2_)\n",
    "        # print('last layer', x1_.shape) \n",
    "        x1_ = self.res_block1(x1_)\n",
    "        print(x1_.shape)\n",
    "        \n",
    "        out = self.out_conv(x1_)\n",
    "        \n",
    "        #print(\"x1 shape: \", x1_.shape)\n",
    "        #print(\"x2 shape: \", x2_.shape)\n",
    "        #print(\"x3 shape: \", x3_.shape)\n",
    "        #print(\"x4 shape: \", x4_.shape) \n",
    "        \n",
    "        return out\n",
    "\n",
    "ch_in = 1\n",
    "h = 128\n",
    "w = 128\n",
    "s = 137\n",
    "b = 2\n",
    "ch_out = 64 \n",
    "k_size = 2\n",
    "input = torch.randn(b, 512).to(torch.float32).to(device)\n",
    "net = Decoder(latent_dim=512, prev_dim = 32*9*8*8).to(device)\n",
    "out = net(input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c945ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff71dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 512\n",
    "prev_dim = 32*9*8*8\n",
    "linear_up = nn.Sequential(nn.Linear(latent_dim, prev_dim//8),\n",
    "                                   nn.BatchNorm1d(prev_dim//8),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(prev_dim//8, prev_dim),\n",
    "                                   nn.BatchNorm1d(latent_dim),\n",
    "                                   nn.ReLU()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43c1a706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35072"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_dim//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e3f260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280576"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e61713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 18, 16, 16])\n",
      "torch.Size([2, 16, 35, 32, 32])\n",
      "torch.Size([2, 8, 69, 64, 64])\n",
      "torch.Size([2, 4, 137, 128, 128])\n",
      "torch.Size([2, 1, 137, 128, 128])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, in_dim = 32*9*8*8, latent_dim=512):\n",
    "        super(VAE, self).__init__()\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.z_mean = nn.Sequential(nn.Linear(in_dim, in_dim//8),\n",
    "                                   nn.BatchNorm1d(in_dim//8),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(in_dim//8, latent_dim),\n",
    "                                   nn.BatchNorm1d(latent_dim),\n",
    "                                   nn.ReLU())\n",
    "        \n",
    "        self.z_log_sigma = nn.Sequential(nn.Linear(in_dim, in_dim//8),\n",
    "                                   nn.BatchNorm1d(in_dim//8),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(in_dim//8, latent_dim),\n",
    "                                   nn.BatchNorm1d(latent_dim),\n",
    "                                   nn.ReLU())\n",
    "        \n",
    "        # self.z_log_sigma = nn.Linear(256*9*8*8, latent_dim)\n",
    "        \n",
    "        #self.z_mean = nn.Linear(256*150, latent_dim)\n",
    "        #self.z_log_sigma = nn.Linear(256*150, latent_dim)\n",
    "        \n",
    "        self.epsilon = torch.normal(size=(1, latent_dim), mean=0, std=1.0, device=self.device)\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "        self.reset_parameters()\n",
    "      \n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            stdv = 1.0 / math.sqrt(weight.size(0))\n",
    "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        #print('encoder shape -', x.shape)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        # print(x.shape)\n",
    "        z_mean = self.z_mean(x)\n",
    "        z_log_sigma = self.z_log_sigma(x)\n",
    "        z = z_mean + z_log_sigma.exp()*self.epsilon\n",
    "        # print(x.shape)\n",
    "        y = self.decoder(z)\n",
    "        return y, z_mean, z_log_sigma\n",
    "\n",
    "\n",
    "model = VAE()\n",
    "model = model.to(device)\n",
    "# B, C, Seq, H, W\n",
    "# input = torch.randn(20, 16, 10, 50, 100).to(torch.float32).to(device)\n",
    "input = torch.randn(2, 1, 137, 128, 128).to(torch.float32).to(device)\n",
    "\n",
    "out = model(input)\n",
    "print(out[0].shape)\n",
    "print(out[1].shape)\n",
    "print(out[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a42d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Size([2, 32, 9, 8, 8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-a100",
   "language": "python",
   "name": "pytorch-a100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
